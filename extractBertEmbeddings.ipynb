{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3e40e8-580e-4940-b4ba-dc0b1d2a3baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"OpenAssistant/oasst1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c97899e-866d-4fb2-8edb-2e52ff9968c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_english(example):\n",
    "    return example[\"lang\"] == \"en\"  # Keep only English text\n",
    "\n",
    "# Apply filtering to all splits\n",
    "ds_en = {split: ds[split].filter(filter_english) for split in ds.keys()}\n",
    "\n",
    "# Check the filtered dataset\n",
    "print(ds_en[\"train\"])\n",
    "print(ds_en[\"validation\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97c0a58-bead-4fac-b7d5-b350fb55f668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only text-related fields\n",
    "fields_to_keep = [\"message_id\", \"parent_id\", \"text\", \"role\"]\n",
    "\n",
    "ds_en_clean = {split: ds_en[split].remove_columns(\n",
    "    [col for col in ds_en[split].column_names if col not in fields_to_keep]\n",
    ") for split in ds_en.keys()}\n",
    "\n",
    "# Display a sample\n",
    "print(ds_en_clean[\"train\"][0:2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cd185e-e193-49c6-baa8-0e65eeb5504c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Convert the dataset to a list of dictionaries, then to a DataFrame\n",
    "df_train = ds_en_clean[\"train\"]\n",
    "df_validation = ds_en_clean[\"validation\"]\n",
    "\n",
    "# Save to CSV\n",
    "df_train.to_csv(\"OpenAssistant_English_Train.csv\", index=False)\n",
    "df_validation.to_csv(\"OpenAssistant_English_Validation.csv\", index=False)\n",
    "\n",
    "print(\"CSV files saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4eddd3-3971-47f3-ab55-e14df8603767",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV files\n",
    "df_train = pd.read_csv(\"OpenAssistant_English_Train.csv\")\n",
    "df_validation = pd.read_csv(\"OpenAssistant_English_Validation.csv\")\n",
    "\n",
    "# Inspect the data\n",
    "print(df_train.head())\n",
    "print(df_validation.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93389aa5-7670-4bfb-95d3-ca3820fcd306",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Extract sentence-level features\n",
    "def extract_style_features(text):\n",
    "    # Sentence length (number of words)\n",
    "    words = text.split()\n",
    "    sentence_length = len(words)\n",
    "\n",
    "    # Punctuation usage\n",
    "    question_marks = text.count(\"?\")\n",
    "    exclamation_marks = text.count(\"!\")\n",
    "\n",
    "    # Vocabulary richness (unique words)\n",
    "    unique_words = len(set(words))\n",
    "    vocabulary_richness = unique_words / len(words) if len(words) > 0 else 0\n",
    "\n",
    "    return {\n",
    "        \"sentence_length\": sentence_length,\n",
    "        \"question_marks\": question_marks,\n",
    "        \"exclamation_marks\": exclamation_marks,\n",
    "        \"vocabulary_richness\": vocabulary_richness,\n",
    "    }\n",
    "\n",
    "# Apply to all messages\n",
    "df_train[\"style_features\"] = df_train[\"text\"].apply(extract_style_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce53ef5-76b0-479a-bfab-2bc6d77c1352",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "# Initialize a directed graph\n",
    "dialogue_graph = nx.DiGraph()\n",
    "\n",
    "# Add nodes and edges\n",
    "for idx, row in df_train.iterrows():\n",
    "    message_id = row[\"message_id\"]\n",
    "    parent_id = row[\"parent_id\"]\n",
    "    text = row[\"text\"]\n",
    "    role = row[\"role\"]\n",
    "\n",
    "    # Add node with attributes\n",
    "    dialogue_graph.add_node(message_id, text=text, role=role)\n",
    "\n",
    "    # Add edge if parent_id exists\n",
    "    if parent_id:\n",
    "        dialogue_graph.add_edge(parent_id, message_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44fe61be-c2a3-4a61-b2b9-9cb62292f19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Visualize a small subgraph (e.g., first 10 nodes)\n",
    "subgraph = dialogue_graph.subgraph(list(dialogue_graph.nodes)[:10])\n",
    "nx.draw(subgraph, with_labels=True, node_color=\"lightblue\", edge_color=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be700a74-a171-4b06-a553-3b460ffd925a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "\n",
    "# Load pre-trained BERT tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = BertModel.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4584c7cb-a4ef-476f-a4c6-e9ed02d935ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_bert_embeddings(text):\n",
    "    # Tokenize input text\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "\n",
    "    # Generate BERT embeddings\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    # Use the [CLS] token embedding as the sentence representation\n",
    "    cls_embedding = outputs.last_hidden_state[:, 0, :].squeeze(0)\n",
    "    print(\"==\")\n",
    "    return cls_embedding\n",
    "\n",
    "# Apply BERT encoding to all messages\n",
    "bert = pd.read_csv(\"combined_features.csv\")\n",
    "df_train[\"bert_embedding\"] = bert[\"bert_embedding\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a639716e-67df-4764-b2b1-398b6d5cb053",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "# Initialize a directed graph\n",
    "dialogue_graph = nx.DiGraph()\n",
    "\n",
    "# Add nodes and edges\n",
    "for idx, row in df_train.iterrows():\n",
    "    message_id = row[\"message_id\"]\n",
    "    parent_id = row[\"parent_id\"]\n",
    "    text = row[\"text\"]\n",
    "    role = row[\"role\"]\n",
    "\n",
    "    # Add node with attributes\n",
    "    dialogue_graph.add_node(message_id, text=text, role=role)\n",
    "\n",
    "    # Add edge if parent_id exists\n",
    "    if parent_id:\n",
    "        dialogue_graph.add_edge(parent_id, message_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fcdc67-1c88-47f8-957a-aaeeb87baef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Extract sentence-level features\n",
    "def extract_style_features(text):\n",
    "    # Sentence length (number of words)\n",
    "    words = text.split()\n",
    "    sentence_length = len(words)\n",
    "\n",
    "    # Punctuation usage\n",
    "    question_marks = text.count(\"?\")\n",
    "    exclamation_marks = text.count(\"!\")\n",
    "\n",
    "    # Vocabulary richness (unique words)\n",
    "    unique_words = len(set(words))\n",
    "    vocabulary_richness = unique_words / len(words) if len(words) > 0 else 0\n",
    "\n",
    "    return {\n",
    "        \"sentence_length\": sentence_length,\n",
    "        \"question_marks\": question_marks,\n",
    "        \"exclamation_marks\": exclamation_marks,\n",
    "        \"vocabulary_richness\": vocabulary_richness,\n",
    "    }\n",
    "\n",
    "# Apply to all messages\n",
    "df_train[\"style_features\"] = df_train[\"text\"].apply(extract_style_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df34c234-8141-4b0f-9298-20968e93224c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def extract_style_features(row):\n",
    "    style_dict = row[\"style_features\"]\n",
    "    return torch.tensor(\n",
    "        [\n",
    "            style_dict[\"sentence_length\"],\n",
    "            style_dict[\"question_marks\"],\n",
    "            style_dict[\"exclamation_marks\"],\n",
    "            style_dict[\"vocabulary_richness\"],\n",
    "        ],\n",
    "        dtype=torch.float,\n",
    "    )\n",
    "\n",
    "# Apply to all rows\n",
    "df_train[\"style_features_tensor\"] = df_train.apply(extract_style_features, axis=1)\n",
    "\n",
    "def combine_features(row):\n",
    "    # BERT embedding (already a tensor)\n",
    "    bert_embedding = row[\"bert_embedding\"]\n",
    "\n",
    "    # Style features (already a tensor)\n",
    "    style_features = row[\"style_features_tensor\"]\n",
    "\n",
    "    # Graph-based features (e.g., node degree, shortest path length)\n",
    "    node_degree = dialogue_graph.degree[row[\"message_id\"]]\n",
    "    shortest_path_length = (\n",
    "        nx.shortest_path_length(dialogue_graph, row[\"parent_id\"], row[\"message_id\"])\n",
    "        if row[\"parent_id\"]\n",
    "        else 0\n",
    "    )\n",
    "    graph_features = torch.tensor([node_degree, shortest_path_length], dtype=torch.float)\n",
    "\n",
    "    # Ensure all tensors are 1-dimensional\n",
    "    bert_embedding = bert_embedding.squeeze()  # Remove extra dimensions if any\n",
    "    style_features = style_features.squeeze()  # Remove extra dimensions if any\n",
    "    graph_features = graph_features.squeeze()  # Remove extra dimensions if any\n",
    "\n",
    "    # Concatenate all features\n",
    "    combined_features = torch.cat([bert_embedding, style_features, graph_features], dim=0)\n",
    "    return combined_features\n",
    "\n",
    "# Apply to all rows\n",
    "# Apply to all rows and store results in a list\n",
    "combined_features_list = []\n",
    "for _, row in df_train.iterrows():\n",
    "    combined_features = combine_features(row)\n",
    "    combined_features_list.append(combined_features)\n",
    "\n",
    "print(combined_features_list[0])\n",
    "\n",
    "# Assign the list to the DataFrame\n",
    "# df_train[\"combined_features\"] = combined_features_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7408d813-92b7-40b9-87b0-3a08eac65960",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train[\"combined_features\"] = df_train.apply(combine_features, axis=1)\n",
    "#\n",
    "# # Convert combined features to a string representation for CSV storage\n",
    "# df_train[\"combined_features\"] = df_train[\"combined_features\"].apply(lambda x: \",\".join(map(str, x)))\n",
    "\n",
    "# Save to CSV\n",
    "df_train.to_csv(\"combined_features.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
